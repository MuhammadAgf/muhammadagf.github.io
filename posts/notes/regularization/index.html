<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">
    <meta name="color-scheme" content="light dark">

    

    <meta name="author" content="Muhammad Assagaf">
    <meta name="description" content="add penalty to the loss function and reduce the value of weight. (introduce bias) $$ Regularized loss = loss &#43; penalty $$ example:
L1 Regularization    or called Lasso add “absolute value of magnitude” coefficient as a penalty term to the loss function (minimize sum of of coefficients/weights)
$$ penalty = \lambda ||w|| = \lambda \sum_{j=1}^M |w|$$
pros:     robust to outliers works best when your model contains a lot of useless features (built-in feature selection) preferred when having a high number of features as it&rsquo;s provide sparse solution  cons:     if there is a high group of higly correlated variables, L1 tend to select 1 variable from the group and ignore the others  L2 Regularization    or called Ridge add “squared magnitude” coefficient as a penalty term to the loss function (minimize sum of square of coefficients/weights)">
    <meta name="keywords" content="blog,developer,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Regularization"/>
<meta name="twitter:description" content="add penalty to the loss function and reduce the value of weight. (introduce bias) $$ Regularized loss = loss &#43; penalty $$ example:
L1 Regularization    or called Lasso add “absolute value of magnitude” coefficient as a penalty term to the loss function (minimize sum of of coefficients/weights)
$$ penalty = \lambda ||w|| = \lambda \sum_{j=1}^M |w|$$
pros:     robust to outliers works best when your model contains a lot of useless features (built-in feature selection) preferred when having a high number of features as it&rsquo;s provide sparse solution  cons:     if there is a high group of higly correlated variables, L1 tend to select 1 variable from the group and ignore the others  L2 Regularization    or called Ridge add “squared magnitude” coefficient as a penalty term to the loss function (minimize sum of square of coefficients/weights)"/>

    <meta property="og:title" content="Regularization" />
<meta property="og:description" content="add penalty to the loss function and reduce the value of weight. (introduce bias) $$ Regularized loss = loss &#43; penalty $$ example:
L1 Regularization    or called Lasso add “absolute value of magnitude” coefficient as a penalty term to the loss function (minimize sum of of coefficients/weights)
$$ penalty = \lambda ||w|| = \lambda \sum_{j=1}^M |w|$$
pros:     robust to outliers works best when your model contains a lot of useless features (built-in feature selection) preferred when having a high number of features as it&rsquo;s provide sparse solution  cons:     if there is a high group of higly correlated variables, L1 tend to select 1 variable from the group and ignore the others  L2 Regularization    or called Ridge add “squared magnitude” coefficient as a penalty term to the loss function (minimize sum of square of coefficients/weights)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://muhammadagf.github.io/posts/notes/regularization/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-10T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2022-12-10T00:00:00&#43;00:00" />



    <title>
  Regularization · Muhammad
</title>

    
      <link rel="canonical" href="https://muhammadagf.github.io/posts/notes/regularization/">
    

    <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>

    
      
      
      <link rel="stylesheet" href="/css/coder.min.0e5ce5b959a68dfe0232c6ddcec1e8ef154517c968464707f3181c437fe611c0.css" integrity="sha256-DlzluVmmjf4CMsbdzsHo7xVFF8loRkcH8xgcQ3/mEcA=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-dark.min.717236c74e0a5208ef73964a9f44c6b443b689a95b270d8b2a40d0c012460dac.css" integrity="sha256-cXI2x04KUgjvc5ZKn0TGtEO2ialbJw2LKkDQwBJGDaw=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="/img/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/img/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    <meta name="generator" content="Hugo 0.83.1" />
  </head>

  
  
    
  
  <body class="preload-transitions colorscheme-auto">
    
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Muhammad
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About Me</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/notes/">Personal notes</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://muhammadagf.github.io/posts/notes/regularization/">
              Regularization
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime='2022-12-10T00:00:00Z'>
                December 10, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              2-minute read
            </span>
          </div>
          
          
          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/machine-learning/">machine-learning</a>
    </span></div>

        </div>
      </header>

      <div>
        
        <hr>
<p>add penalty to the loss function and reduce the value of weight. (introduce <strong>bias</strong>)
$$ Regularized loss = loss + penalty $$
example:</p>
<h3 id="l1-regularization">
  L1 Regularization
  <a class="heading-link" href="#l1-regularization">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<p>or called Lasso add “absolute value of magnitude” coefficient as a penalty term to the loss function
(minimize sum of of coefficients/weights)</p>
<p>$$ penalty =  \lambda ||w|| = \lambda \sum_{j=1}^M |w|$$</p>
<h5 id="pros">
  pros:
  <a class="heading-link" href="#pros">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h5>
<ol>
<li>robust to outliers</li>
<li>works best when your model contains a lot of useless features (built-in <a href="https://muhammadagf.github.io/posts/notes/feature-selection/">feature selection</a>)
<strong>preferred when having a high number of features as it&rsquo;s provide sparse solution</strong></li>
</ol>
<h5 id="cons">
  cons:
  <a class="heading-link" href="#cons">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h5>
<ol>
<li>if there is a high group of higly correlated variables, L1 tend to select 1 variable from the group and ignore the others</li>
</ol>
<h4 id="l2-regularization">
  L2 Regularization
  <a class="heading-link" href="#l2-regularization">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<p>or called Ridge add  “squared magnitude” coefficient as a penalty term to the loss function (minimize sum of square of coefficients/weights)</p>
<p>$$ penalty = \lambda w^Tw = \lambda \sum_{j=1}^M w^2$$</p>
<h5 id="pros-1">
  pros:
  <a class="heading-link" href="#pros-1">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h5>
<ol>
<li>can deal with <strong>multicollinearity</strong> (independent variable are higly-correlated) problems through by reducing the impact/weight of correlated predictors/features but keeping all predictors in the model</li>
</ol>
<h4 id="elasticnet">
  Elasticnet
  <a class="heading-link" href="#elasticnet">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<p>combined of L1 and L2
$$ penalty = \lambda_1 ||w|| + \lambda_2 w^Tw$$</p>
<h3 id="comments">
  Comments:
  <a class="heading-link" href="#comments">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<style type="text/css">.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}</style>
<div><svg width="0" height="0" display="none" xmlns="http://www.w3.org/2000/svg"><symbol id="tip-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"/></symbol><symbol id="note-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="warning-notice" viewBox="0 0 576 512" preserveAspectRatio="xMidYMid meet"><path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="info-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></symbol></svg></div><div class="notice note" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"></use></svg></span>Note</p><p><strong>higher $\lambda$ we will get smaller slope (less and less sensitive to weight)</strong></p></div>

<table>
<thead>
<tr>
<th>L1</th>
<th>L2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Penalized Sum of absolute w</td>
<td>penalized sum of squared w</td>
</tr>
<tr>
<td>sparse solution</td>
<td>non sparse solution</td>
</tr>
<tr>
<td>multiple solution solution</td>
<td>only has 1 solution</td>
</tr>
<tr>
<td>built-in <a href="https://muhammadagf.github.io/posts/notes/feature-selection/">feature selection</a></td>
<td>no feature selection</td>
</tr>
<tr>
<td>simple and interpretable</td>
<td>more accurate when output variable are functions of all input variables</td>
</tr>
<tr>
<td>robust to outliers</td>
<td>not robust to outliers</td>
</tr>
<tr>
<td>can&rsquo;t learn complex pattern</td>
<td>can learn complex pattern</td>
</tr>
<tr>
<td>Computationally inefficient over non-sparse conditions.</td>
<td>having analytical solutions.</td>
</tr>
</tbody>
</table>
<hr>
<h1 id="references">
  References
  <a class="heading-link" href="#references">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<ol>
<li><a href="https://www.analyticssteps.com/blogs/l2-and-l1-regularization-machine-learning">https://www.analyticssteps.com/blogs/l2-and-l1-regularization-machine-learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Elastic_net_regularization">https://en.wikipedia.org/wiki/Elastic_net_regularization</a></li>
<li>elastic: <a href="https://www.youtube.com/watch?v=1dKRdX9bfIo">https://www.youtube.com/watch?v=1dKRdX9bfIo</a></li>
</ol>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
    integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
    integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body,
      {
        delimiters: [
          {left: '$$', right: '$$', display:true},
          {left: '$', right: '$', display:false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ]
      }
    );"></script>
  </section>

      </div>

      
  <footer class="footer">
    <section class="container">
      
        <p>More to Come</p>
      
      
        ©
        
        2023
         Muhammad Assagaf 
      
      
         · 
        Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
      
      
    </section>
  </footer>


    </main>

    
      
      <script src="/js/coder.min.03b17769f4f91ae35667e1f2a1ca8c16f50562576cf90ff32b3179926914daa5.js" integrity="sha256-A7F3afT5GuNWZ&#43;HyocqMFvUFYlds&#43;Q/zKzF5kmkU2qU="></script>
    

    

    

    

    

    

    

    

    
  </body>

</html>
