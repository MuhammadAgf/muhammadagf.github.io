<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning lifecycle on Muhammad</title>
    <link>https://muhammadagf.github.io/tags/machine-learning-lifecycle/</link>
    <description>Recent content in machine learning lifecycle on Muhammad</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 17 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://muhammadagf.github.io/tags/machine-learning-lifecycle/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Model Debugging</title>
      <link>https://muhammadagf.github.io/posts/notes/model-debugging/</link>
      <pubDate>Sat, 17 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/model-debugging/</guid>
      <description>Model performance analysis goes beyond simple metrics and focuses on model robustness. Model debugging is a discipline that aims to improve model robustness. .notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} Tip
Robustness refers to the consistency of a model&amp;rsquo;s accuracy when features change.
 Objectives of model debugging include: improving model transparency, reducing discrimination, addressing vulnerabilities, and managing performance decay.</description>
    </item>
    
    <item>
      <title>Model Remediation</title>
      <link>https://muhammadagf.github.io/posts/notes/model-remediation/</link>
      <pubDate>Sat, 17 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/model-remediation/</guid>
      <description>ways to improve model robustness:
Data Augmentation    data augmentation can help generalize the model and reduce sensitivity and useful for correcting unbalanced data.
 Ensure training data accurately represents the requests your model will receive. Generate data through techniques like generative or interpretive methods, or by adding noise..  Explainable AI (XAI)     Understand the inner workings of your model to improve robustness. Tools and techniques are available to enhance model interpretability.</description>
    </item>
    
    <item>
      <title>Sensitivity Analysis</title>
      <link>https://muhammadagf.github.io/posts/notes/sensitivity-analysis/</link>
      <pubDate>Sat, 17 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/sensitivity-analysis/</guid>
      <description>Sensitivity analysis helps understand a model&amp;rsquo;s behavior by examining the impact of each feature on predictions.
It involves changing a single feature while keeping others constant and observing the resulting model outputs. The magnitude of change in predictions indicates the feature&amp;rsquo;s influence.
Techniques for sensitivity analysis include:
 Random attacks: Generating random input data to test model outputs and uncover unexpected bugs. Partial dependence plots: Show marginal effect of 1 or 2 feature and it&amp;rsquo;s effect to the result of the model  PDPbox and PyCEbox are open-source packages for creating partial dependence plots.</description>
    </item>
    
    <item>
      <title>Data Distribution Changes</title>
      <link>https://muhammadagf.github.io/posts/notes/data-distribution-changes/</link>
      <pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/data-distribution-changes/</guid>
      <description>Data Drift and Skew     Drift refers to changes in data over time. It occurs when there are changes in the statistical properties of the features between different time periods or data collections. Skew is the difference between two versions of the same dataset from different sources. It can be caused by changes in the data schema or distribution.  Model Decay and Data Issues     Model decay refers to the decline in model performance over time, which is often caused by data drift and concept drift.</description>
    </item>
    
    <item>
      <title>Feature Engineering</title>
      <link>https://muhammadagf.github.io/posts/notes/feature-engineering/</link>
      <pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/feature-engineering/</guid>
      <description>Preprocessing      Data Cleansing: To eliminate or correct erroneous data by identifying and handling inconsistencies or outliers.
  Scaling and Normalizing: Numerical features often need to be scaled or normalized to ensure the models can learn effectively. Scaling adjusts the range of features, while normalization brings them within a specific range, such as between 0 and 1.
  dimensionality Reduction: Reducing the number of features by creating a lower-dimensional representation of the data.</description>
    </item>
    
    <item>
      <title>Data Augmentation</title>
      <link>https://muhammadagf.github.io/posts/notes/data-augmentation/</link>
      <pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/data-augmentation/</guid>
      <description>Data augmentation is a valuable technique for increasing the amount of data available for training machine learning models, particularly for unstructured data like images, audio, and text.
However, when applying data augmentation, it is important to make thoughtful decisions. Here are some best practices to consider:
  Goal of Data Augmentation: The purpose of data augmentation is to generate examples that challenge the learning algorithm, while still being recognizable by humans or a baseline algorithm.</description>
    </item>
    
    <item>
      <title>Data Labeling Conventions</title>
      <link>https://muhammadagf.github.io/posts/notes/data-labeling-conventions/</link>
      <pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/data-labeling-conventions/</guid>
      <description>Improving Label Consistency    To enhance the consistency of labels in a project, follow these steps:
  Multiple Labelers: If label consistency is a concern, select a few examples and have multiple labelers assign labels to them. This approach helps identify inconsistencies among labelers.
  Relabeling: Allow the same labeler to relabel an example after a break or time gap, encouraging consistency even within individual labelers.</description>
    </item>
    
    <item>
      <title>Obtaining Data</title>
      <link>https://muhammadagf.github.io/posts/notes/obtaining-data/</link>
      <pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/obtaining-data/</guid>
      <description>How long should you spend obtaining data?    source: https://www.coursera.org/learn/introduction-to-machine-learning-in-production/lecture/Y7zTm/obtaining-data
  Define the data requirements: Determine what data is needed for the project, including the definition of the target variable (y) and input variables (x).
  Time investment: Consider the time spent on obtaining data in relation to the iterative process of machine learning. It is recommended to enter the iteration loop quickly by not spending excessive time on data collection initially.</description>
    </item>
    
    <item>
      <title>Error Analysis In Machine Learning</title>
      <link>https://muhammadagf.github.io/posts/notes/error-analysis-in-machine-learning/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/error-analysis-in-machine-learning/</guid>
      <description>When training a learning algorithm for the first time, it is expected that it won&amp;rsquo;t work perfectly right away. The key to improving its performance lies in error analysis. By analyzing the errors made by the algorithm, we can determine the most efficient use of our time in improving its performance.
Example: Speech Recognition Error Analysis    To illustrate the error analysis process, let&amp;rsquo;s consider an example of speech recognition.</description>
    </item>
    
    <item>
      <title>Establish A Baselines</title>
      <link>https://muhammadagf.github.io/posts/notes/establish-a-baselines/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/establish-a-baselines/</guid>
      <description>When starting a machine learning project, it is essential to establish a baseline level of performance before making improvements. This baseline serves as a point of comparison and helps determine where to focus efforts.
Establishing a Baseline     Determine major categories in your data. for speech recognition: (e.g., clear speech, speech with car noise, speech with people noise, low bandwidth audio). Measure accuracy for each category (e.</description>
    </item>
    
    <item>
      <title>Get Started In Modelling</title>
      <link>https://muhammadagf.github.io/posts/notes/get-started-in-modelling/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/get-started-in-modelling/</guid>
      <description>Tips for Getting Started    When starting a machine learning project, there are several tips to consider for efficient progress.
Getting Started on Modeling     Conduct a literature search to understand existing approaches and possibilities. Focus on practical implementations instead of the latest algorithms. Open source implementations can provide a baseline and facilitate quick start. A reasonable algorithm with good data often outperforms a cutting-edge algorithm with poor data.</description>
    </item>
    
    <item>
      <title>Ml Deployment Patterns And Degrees Of Automation</title>
      <link>https://muhammadagf.github.io/posts/notes/ml-deployment-patterns-and-degrees-of-automation/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/ml-deployment-patterns-and-degrees-of-automation/</guid>
      <description>Use Cases:    Offering a new product or capability:    When introducing a new service like speech recognition, a common design pattern is to start with a small amount of traffic and gradually increase it.
Automating or assisting existing tasks:    If a task previously performed by humans, like inspecting smartphones for defects, can be automated or assisted by a learning algorithm, a shadow mode deployment can be used.</description>
    </item>
    
    <item>
      <title>Machine Learning Lifecycle</title>
      <link>https://muhammadagf.github.io/posts/notes/machine-learning-lifecycle/</link>
      <pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/machine-learning-lifecycle/</guid>
      <description>Scoping:
 Define the project. Decide on key metrics. Estimate resources, and timeline.    Data:
 Define data.  establish a baselines, and address data labeling inconsistencies. obtaining data.   Standardize data labeling conventions.  Advanced Labeling Technique:  Semi-supervised Learning Active Learning Weak Supervision        Modeling: To get started in modelling there are 3 key input: Code (algorithm/model), Hyperparameter, Data.</description>
    </item>
    
    <item>
      <title>Ml Model Deployment</title>
      <link>https://muhammadagf.github.io/posts/notes/ml-model-deployment/</link>
      <pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/ml-model-deployment/</guid>
      <description>Issues:    ML/Statistical Issue:    Given a data X, model F and output y, we have a data distribution changes Issue called: Concept drift and Data drift.
Concept Drift    refer to when desired mapping from X to y changes. for example due to inflation, same size of the house can be priced higher.
Data Drift    refer to when the input distribution (X) changes.</description>
    </item>
    
  </channel>
</rss>
