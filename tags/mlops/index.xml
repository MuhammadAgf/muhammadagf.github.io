<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mlops on Muhammad</title>
    <link>https://muhammadagf.github.io/tags/mlops/</link>
    <description>Recent content in mlops on Muhammad</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 19 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://muhammadagf.github.io/tags/mlops/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ml Batch Processing</title>
      <link>https://muhammadagf.github.io/posts/notes/ml-batch-inference/</link>
      <pubDate>Mon, 19 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/ml-batch-inference/</guid>
      <description>source: Feature Stores for ML, 2021
Batch Inference and ETL Pipelines    Batch inference involves using machine learning models to generate predictions for a large number of data points in a batch or scheduled manner, without the need for real-time information.
Batch Inference    Batch inference is used when predictions are not required immediately and can be generated on a recurring schedule, such as daily or weekly.</description>
    </item>
    
    <item>
      <title>Ml Experiment Tracking</title>
      <link>https://muhammadagf.github.io/posts/notes/ml-experiment-tracking/</link>
      <pubDate>Mon, 19 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/ml-experiment-tracking/</guid>
      <description>Experiment tracking is the process of managing all the different experiments and their components, such as parameters, metrics, models and other artifacts.
Running experiments without proper tools can easily result in a disorganized and unmanageable workflow, even for simple projects. As a data scientist, it is essential to choose the right experiment tracking tool that best fits your needs and workflow.
Why Tracking an experiment:     Small changes in models and data can significantly impact performance and resource requirements, emphasizing the importance of tracking even minor changes.</description>
    </item>
    
    <item>
      <title>Mlops</title>
      <link>https://muhammadagf.github.io/posts/notes/mlops/</link>
      <pubDate>Mon, 19 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/mlops/</guid>
      <description>Introduction to MLOps    MLOps, or Machine Learning Operations, refers to the practices and processes involved in managing and deploying machine learning models in production. It combines the principles of software engineering and DevOps with the unique challenges presented by machine learning systems.
source: https://neptune.ai/blog/mlops
Challenges in ML Engineering    There are several challenges in ML engineering that drive the need for MLOps:
  Slow Deployment: Deploying ML models to production can take days, weeks or even months.</description>
    </item>
    
    <item>
      <title>Ml Model Serving</title>
      <link>https://muhammadagf.github.io/posts/notes/ml-model-serving/</link>
      <pubDate>Sun, 18 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/ml-model-serving/</guid>
      <description>Infrastructure for Model Serving    two main options for infrastructure:
  On-Premises: In this approach, you have all the hardware and software required for running your models on your own premises.
 pros: provides you with complete control and flexibility to adapt to changes quickly. cons: it can be complicated and expensive to procure, install, configure, and maintain the hardware infrastructure.    Cloud Provider: Alternatively, you can outsource your infrastructure needs to a cloud provider like Amazon Web Services, Google Cloud Platform, or Microsoft Azure.</description>
    </item>
    
    <item>
      <title>Pipeline Prallelism</title>
      <link>https://muhammadagf.github.io/posts/notes/pipeline-prallelism/</link>
      <pubDate>Tue, 13 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/pipeline-prallelism/</guid>
      <description>ETL Problem:    Transformations and preprocessing tasks add overhead to the training input pipeline.
Commons ETL: source: https://community.deeplearning.ai/t/mlep-course-3-lecture-notes/54454
Problem:
 Input pipelines are needed to supply enough data fast enough to keep accelerators busy. Pre-processing tasks and data size can add overhead to the training input pipeline.  Improved Input Pipeline:     Parallel processing of data is essential to utilize compute, IO, and network resources effectively.</description>
    </item>
    
    <item>
      <title>Distributed Training</title>
      <link>https://muhammadagf.github.io/posts/notes/distributed-training/</link>
      <pubDate>Sun, 04 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/distributed-training/</guid>
      <description>Distributed training allows for training huge models and speeding up the training process.
Types:    Data parallelism    Dividing data into partitions and copying the complete model to all workers. Each worker operates on a different partition, and model updates are synchronized across workers. source: https://community.deeplearning.ai/t/mlep-course-3-lecture-notes/
  Synchronous training: (example: all-reduce architecture) Workers train on it&amp;rsquo;s current mini-batches of data, apply updates, and wait for updates from other workers before proceeding.</description>
    </item>
    
    <item>
      <title>Ml Deployment Patterns And Degrees Of Automation</title>
      <link>https://muhammadagf.github.io/posts/notes/ml-deployment-patterns-and-degrees-of-automation/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/ml-deployment-patterns-and-degrees-of-automation/</guid>
      <description>Use Cases:    Offering a new product or capability:    When introducing a new service like speech recognition, a common design pattern is to start with a small amount of traffic and gradually increase it.
Automating or assisting existing tasks:    If a task previously performed by humans, like inspecting smartphones for defects, can be automated or assisted by a learning algorithm, a shadow mode deployment can be used.</description>
    </item>
    
    <item>
      <title>Machine Learning Lifecycle</title>
      <link>https://muhammadagf.github.io/posts/notes/machine-learning-lifecycle/</link>
      <pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/machine-learning-lifecycle/</guid>
      <description>Check: MLOps (mlops) as well.
  Scoping:
 Define the project. Decide on key metrics. Estimate resources, and timeline.    Data:
 Define data.  establish a baselines, and address data labeling inconsistencies. obtaining data.   Standardize data labeling conventions.  Advanced Labeling Technique:  Semi-supervised Learning Active Learning Weak Supervision        Modeling: To get started in modelling there are 3 key input: Code (algorithm/model), Hyperparameter, Data.</description>
    </item>
    
    <item>
      <title>Ml Model Deployment</title>
      <link>https://muhammadagf.github.io/posts/notes/ml-model-deployment/</link>
      <pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://muhammadagf.github.io/posts/notes/ml-model-deployment/</guid>
      <description>Issues:    ML/Statistical Issue:    Given a data X, model F and output y, we have a data distribution changes Issue called: Concept drift and Data drift.
Concept Drift    refer to when desired mapping from X to y changes. for example due to inflation, same size of the house can be priced higher.
Data Drift    refer to when the input distribution (X) changes.</description>
    </item>
    
  </channel>
</rss>
